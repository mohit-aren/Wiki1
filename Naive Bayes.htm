<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0cm;
	margin-right:0cm;
	margin-bottom:8.0pt;
	margin-left:0cm;
	line-height:107%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
h3
	{mso-style-link:"Heading 3 Char";
	margin-right:0cm;
	margin-left:0cm;
	font-size:13.5pt;
	font-family:"Times New Roman",serif;
	font-weight:bold;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:#954F72;
	text-decoration:underline;}
p
	{margin-right:0cm;
	margin-left:0cm;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.Heading3Char
	{mso-style-name:"Heading 3 Char";
	mso-style-link:"Heading 3";
	font-family:"Times New Roman",serif;
	font-weight:bold;}
p.ql-center-displayed-equation, li.ql-center-displayed-equation, div.ql-center-displayed-equation
	{mso-style-name:ql-center-displayed-equation;
	margin-right:0cm;
	margin-left:0cm;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.ql-right-eqno
	{mso-style-name:ql-right-eqno;}
span.ql-left-eqno
	{mso-style-name:ql-left-eqno;}
span.crayon-sy
	{mso-style-name:crayon-sy;}
span.crayon-s
	{mso-style-name:crayon-s;}
span.crayon-h
	{mso-style-name:crayon-h;}
.MsoChpDefault
	{font-family:"Calibri",sans-serif;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:107%;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>

</head>

<body lang=EN-IN link=blue vlink="#954F72">

<div class=WordSection1>

<p class=MsoNormal align=center style='text-align:center'><a
name="_Hlk497473051"></a><b><span style='font-size:13.5pt;line-height:107%;
font-family:"Arial",sans-serif;color:#2B3E51;background:white'>Machine Learning
Using Naïve Bayes Classification</span></b></p>

<p class=MsoNormal><b><span style='font-size:13.5pt;line-height:107%;
font-family:"Arial",sans-serif;color:#2B3E51;background:white'>Abstract:</span></b></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>It is very needful problem
in current scenario to predict the text category of a new data from existing
categories data. In this page we have tried to explore Bayesian probability
approach to predict the class of new text.</span></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>It uses the probability that
new text belongs to which category with a numeric score. The maximum score will
tell which category the new query text belongs to. This process is easy and
works to good accuracy.</span></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>&nbsp;</span></p>

<p class=MsoNormal><b><span style='font-size:13.5pt;line-height:107%;
font-family:"Arial",sans-serif;color:#2B3E51;background:white'>Introduction:</span></b></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>&nbsp;</span></p>

<p class=MsoNormal><b><span style='font-size:13.5pt;line-height:107%;
font-family:"Arial",sans-serif;color:#2B3E51;background:white'>Naive Bayes</span></b><span
style='font-size:13.5pt;line-height:107%;font-family:"Arial",sans-serif;
color:#2B3E51;background:white'> are also known as&nbsp;<b>Naive Bayes
Classifiers.</b>&nbsp;It works with the assumption that features are&nbsp;</span><a
href="https://brilliant.org/wiki/statistical-independence/?wiki_title=statistically%20independent"
target="_blank" title="page not yet created"><span style='font-size:13.5pt;
line-height:107%;font-family:"Arial",sans-serif;color:#2B3E51;background:white;
text-decoration:none'>statistically independent</span></a><span
style='font-size:13.5pt;line-height:107%;font-family:"Arial",sans-serif;
color:#2B3E51;background:white'>&nbsp;of one another. Unlike many other
classifiers which assume that, for a given class, there will be some&nbsp;</span><a
href="https://brilliant.org/wiki/correlation/" target="_blank"
title=correlation><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white;text-decoration:none'>correlation</span></a><span
style='font-size:13.5pt;line-height:107%;font-family:"Arial",sans-serif;
color:#2B3E51;background:white'>&nbsp;between features, naive Bayes explicitly assumes
the features as&nbsp;</span><a
href="https://brilliant.org/wiki/conditional-independence/?wiki_title=conditionally%20independent"
target="_blank" title="page not yet created"><span style='font-size:13.5pt;
line-height:107%;font-family:"Arial",sans-serif;color:#2B3E51;background:white;
text-decoration:none'>conditionally independent</span></a><span
style='font-size:13.5pt;line-height:107%;font-family:"Arial",sans-serif;
color:#2B3E51;background:white'>&nbsp;given the class. While this seems an
overly simplistic (naive) restriction on the data, in practice naive Bayes is
competitive with more sophisticated techniques and enjoys some theoretical
support for its presumption.</span></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>Because of the independence
assumption, naive Bayes classifiers are highly scalable and can quickly learn
to use high dimensional features with limited training data. This is useful for
many real world datasets where the amount of data may be small in comparison
with the number of features for each individual piece of data, such as speech, text,
and image data. Examples of modern applications include recommendation system, spam
filtering, automatic medical diagnoses, medical image processing, and vocal
emotion recognition.</span></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>&nbsp;</span></p>

<p class=MsoNormal><b><span style='font-size:13.5pt;line-height:107%;
font-family:"Arial",sans-serif;color:#2B3E51;background:white'>Example with
Naïve Bayes</span></b></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>Suppose we are building a
classifier that checks from symptoms text whether disease is cough or
conjunctivitis. Our training set has 255 sentences for cough and 255 for
conjunctivitis, some examples are listed below:</span></p>

<p class=MsoNormal><span style='font-size:13.5pt;line-height:107%;font-family:
"Arial",sans-serif;color:#2B3E51;background:white'>&nbsp;</span></p>

<table class=MsoNormalTable border=1 cellspacing=0 cellpadding=0 width=616
 style='width:462.0pt;background:white;border-collapse:collapse;border:none'>
 <tr style='height:11.25pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;padding:
  .75pt .75pt .75pt .75pt;height:11.25pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Text</span></b></p>
  </td>
  <td width=207 style='width:155.25pt;border:solid windowtext 1.0pt;border-left:
  none;padding:.75pt .75pt .75pt .75pt;height:11.25pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Disease</span></b></p>
  </td>
 </tr>
 <tr style='height:42.0pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;border-top:
  none;padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Watery eyes and itchy nose</span></p>
  </td>
  <td width=207 style='width:155.25pt;border-top:none;border-left:none;
  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;
  padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Conjunctivitis</span></p>
  </td>
 </tr>
 <tr style='height:42.0pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;border-top:
  none;padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>and the sneezing and coughing begin</span></p>
  </td>
  <td width=207 style='width:155.25pt;border-top:none;border-left:none;
  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;
  padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Cough</span></p>
  </td>
 </tr>
 <tr style='height:42.0pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;border-top:
  none;padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>my eyes are like forever itchy what should i do</span></p>
  </td>
  <td width=207 style='width:155.25pt;border-top:none;border-left:none;
  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;
  padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Conjunctivitis</span></p>
  </td>
 </tr>
 <tr style='height:42.0pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;border-top:
  none;padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>When you start coughing and then you</span></p>
  </td>
  <td width=207 style='width:155.25pt;border-top:none;border-left:none;
  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;
  padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Cough</span></p>
  </td>
 </tr>
 <tr style='height:42.0pt'>
  <td width=393 style='width:294.75pt;border:solid windowtext 1.0pt;border-top:
  none;padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>my eyes so watery</span></p>
  </td>
  <td width=207 style='width:155.25pt;border-top:none;border-left:none;
  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;
  padding:.75pt .75pt .75pt .75pt;height:42.0pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
  color:#2B3E51'>Conjunctivitis</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal>&nbsp;</p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Now, which category does the symptom&nbsp;“<i>I have red eyes
and nose”</i>&nbsp;belong to?</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Since Naive Bayes is a probabilistic classifier, we want to
calculate the probability that the symptom&nbsp;“<i>I have red eyes and nose”</i>
is Cough, and the probability that it’s&nbsp;<em><span style='font-family:"Arial",sans-serif'>Conjunctivitis</span></em>.
Then, we take the largest one. Written mathematically, what we want
is&nbsp;P(Cough | I have red eyes and nose ) — the probability that the
category of a disease symptom is&nbsp;Cough&nbsp;given that the sentence is “I
have red eyes and nose”.</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>To get the probability we need to convert text to numeric
values. For this we can use word frequencies and count of distinct words and
total words and use them to compute probabilities.</span></p>

<p class=MsoNormal style='line-height:normal;background:white'><b><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Bayes’
Theorem</span></b></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Now
we need to transform the probability we want to calculate into something that
can be calculated using word frequencies. </span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Bayes’
Theorem is useful when working with conditional probabilities (like we are
doing here), because it provides us with a way to reverse them:</span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:33.0pt;background:
white'><span style='font-size:15.0pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;&nbsp;</span>
<img border=0 width=269 height=70 id="Picture 1"
src="Naive%20Bayes_files/image001.png"></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>In
our case, we have&nbsp;</span><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>P(Cough | I have red eyes and nose )</span><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>, so
using this theorem we can reverse the conditional probability:</span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:15.0pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;&nbsp;</span><span
style='font-size:10.0pt;font-family:"Arial",sans-serif;color:#0070C0'>P(Cough |
I have red eyes and nose ) = P(I have red eyes and nose | Cough ) * P(Cough)/
P(I have red eyes and nose )</span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Since
for our classifier we’re just trying to find out which category has a bigger
probability, we can discard the divisor&nbsp;—which is the same for both diseases
- and just compare</span></p>

<p class=MsoNormal align=center style='margin-bottom:15.0pt;text-align:center;
line-height:normal;background:white'><span style='font-size:10.0pt;font-family:
"Arial",sans-serif;color:#0070C0'>P(I have red eyes and nose | Cough ) *
P(Cough)</span></p>

<p class=MsoNormal align=center style='margin-bottom:15.0pt;text-align:center;
line-height:normal;background:white'><span style='font-size:13.5pt;font-family:
"Arial",sans-serif;color:#2B3E51'>with</span></p>

<p class=MsoNormal align=center style='margin-bottom:15.0pt;text-align:center;
line-height:normal;background:white'><span style='font-size:10.0pt;font-family:
"Arial",sans-serif;color:#0070C0'>P(I have red eyes and nose | Conjunctivitis )
* P(Conjunctivitis)</span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>This
is better, since we could actually calculate these probabilities.</span></p>

<p class=MsoNormal style='margin-bottom:15.0pt;line-height:normal;background:
white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>There’s
a problem though: “</span><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>I have red eyes and nose</span><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>” doesn’t appear in our training
set, so this probability is zero. Unless every sentence that we want to
classify appears in our training set, the model won’t be very useful.</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><b><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Naïve Bayes Theorem</span></b></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>This can be seen from the equation of form:</span><img border=0
width=443 height=80 id="Picture 16" src="Naive%20Bayes_files/image002.png"></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Or</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'><img border=0 width=454 height=87 id="Picture 17"
src="Naive%20Bayes_files/image003.png"></span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>So here comes the&nbsp;<em><span style='font-family:"Arial",sans-serif'>Naive</span></em>&nbsp;part:
we assume that every word in a sentence is&nbsp;</span><strong><span
style='font-family:"Arial",sans-serif;color:#2B3E51'>independent</span></strong><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;of
the other ones. This means that we’re no longer looking at entire sentences,
but rather at individual words. We write this as:</span></p>

<p align=center style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;
margin-left:0cm;text-align:center;background:white'><span style='font-size:
13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>P(I have red eyes and nose
) = P(I) * P(have) * P(red) * P(eyes) * P(and) * P(nose)</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>This assumption is very strong&nbsp;but very useful. It makes
this model work well with little data. The next step is just applying this to
what we had before:</span></p>

<p align=center style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;
margin-left:0cm;text-align:center;background:white'><span style='font-size:
13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>P(I have red eyes and nose
| Cough ) = P(I | Cough) * P(have | Cough) * P(red | Cough) * P(eyes | Cough) *
P(and | Cough) * P(nose | Cough)</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>&nbsp;</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>And now, all of these individual words actually show up several
times in our training set, and we can calculate them.</span></p>

<h3 style='background:white'><span style='font-family:"Arial",sans-serif;
color:#2B3E51'>Calculating probabilities</span></h3>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>The final step is just to calculate every probability and see
which one turns out to be larger.</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Calculating a probability is just counting in our training set.</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>First, we calculate the a priori probability of each category:
for a given sentence in our training set, the probability that it is&nbsp;</span><em><span
style='font-family:"Arial",sans-serif;color:#2B3E51'>Cough</span></em><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;P(Sports)
is </span><span style='font-size:13.5pt;font-family:"Cambria Math",serif;
color:#2B3E51'>255/510</span><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>. Then, P(Conjunctivitis) is </span><span style='font-size:13.5pt;
font-family:"Cambria Math",serif;color:#2B3E51'>255/510</span><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>. That’s
easy to compute.</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Then, calculating&nbsp;P(nose | Cough) means counting how many
times the word “nose” appears in&nbsp;</span><em><span style='font-family:"Arial",sans-serif;
color:#2B3E51'>Cough</span></em><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>&nbsp;samples (255) divided by the total number of words
in&nbsp;</span><em><span style='font-family:"Arial",sans-serif;color:#2B3E51'>Cough</span></em><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>. </span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>However, we run into a problem here: “red” doesn’t appear in
any&nbsp;<i>Cough</i>&nbsp;sample! That means that&nbsp;P(red | Cough) =
0.&nbsp; This is rather not helping since we are going to be multiplying it
with the other probabilities, so we’ll end up P(I have red eyes and nose |
Cough )  = 0. Doing things this way will not give information at all.</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>We solve
it using </span><a href="https://en.wikipedia.org/wiki/Laplace_smoothing"
target="_blank"><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#007BE2;text-decoration:none'>Laplace smoothing</span></a><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>: we add
1 to every count so it’s never zero. To balance this, we add the number of
possible words (total distinct words in both samples) to the divisor, so the
division will never be greater than 1. </span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Thus P(eyes
| Cough ) = (frequency of eyes in Cough samples) + 1)/(total words in Cough
samples + total distinct words in both sample)</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'> = (91
+1)/(3168 + 1827) = 0.0184</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>Doing in
this we get:</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>&nbsp;</span></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>P(I have
red eyes and nose | Cough ) = </span><b><span style='font-family:"Arial",sans-serif;
color:#0066FF'>7.77280828952263E-17</span></b></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><b><span
style='font-family:"Arial",sans-serif;color:#0066FF'>&nbsp;</span></b></p>

<p style='margin:0cm;margin-bottom:.0001pt;background:white'><span
style='font-size:13.5pt;font-family:"Arial",sans-serif;color:#2B3E51'>P(I have
red eyes and nose | Conjunctivitis ) = </span><b><span style='font-family:"Arial",sans-serif;
color:#0066FF'>4.57427484108468E-14</span></b></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>&nbsp;</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>Hence our classifier gives <span style='background:white'>“</span>I
have red eyes and nose<span style='background:white'>” the&nbsp;<strong><span
style='font-family:"Arial",sans-serif'>Conjunctivitis</span></strong>&nbsp;category.</span></span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><b><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51;background:white'>References</span></b></p>

<p style='margin-left:18.0pt;background:white'><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>[1] A Bayesian Classification
Approach Using Class-Specific Features for Text Categorization, Bo Tang,
Student Member, IEEE, Haibo He, Senior Member, IEEE, Paul M. Baggenstoss,
Senior Member, IEEE, and Steven Kay, Fellow, IEEE, IEEE TRANSACTIONS ON
KNOWLEDGE AND DATA ENGINEERING, VOL. 28, NO. 6, JUNE 2016.</span></p>

<p style='margin-left:18.0pt;background:white'><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>[2] Halftone Image Classification
Using LMS Algorithm and Naive Bayes, Yun-Fu Liu, Student Member, IEEE,
Jing-Ming Guo, Senior Member, IEEE, and Jiann-Der Lee, Member, IEEE, IEEE
TRANSACTIONS ON IMAGE PROCESSING, VOL. 20, NO. 10, OCTOBER 2011.</span></p>

<p style='margin-left:18.0pt;background:white'><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>[3] Internet Traffic
Classification by Aggregating Correlated Naive Bayes Predictions, Jun Zhang,
Member, IEEE, Chao Chen, Yang Xiang, Senior Member, IEEE, Wanlei Zhou, Senior
Member, IEEE, and Yong Xiang, Senior Member, IEEE, IEEE TRANSACTIONS ON
INFORMATION FORENSICS AND SECURITY, VOL. 8, NO. 1, JANUARY 2013.</span></p>

<p style='margin-left:18.0pt;background:white'><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>[4] Some Effective Techniques for
Naive Bayes Text Classification, Sang-Bum Kim, Kyoung-Soo Han, Hae-Chang Rim,
and Sung Hyon Myaeng, IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL.
18, NO. 11, NOVEMBER 2006</span></p>

<p style='margin-left:18.0pt;background:white'><span style='font-size:13.5pt;
font-family:"Arial",sans-serif;color:#2B3E51'>[5] Toward Optimal Feature
Selection in Naive Bayes for Text Categorization, Bo Tang, Student Member,
IEEE, Steven Kay, Fellow, IEEE, and Haibo He, IEEE TRANSACTIONS ON KNOWLEDGE
AND DATA ENGINEERING, VOL. 28, NO. 9, SEPTEMBER 2016</span></p>

<p style='margin-top:0cm;margin-right:0cm;margin-bottom:15.0pt;margin-left:
0cm;background:white'><span style='font-size:13.5pt;font-family:"Arial",sans-serif;
color:#2B3E51'>&nbsp;</span></p>

<p class=MsoNormal>&nbsp;</p>

</div>

</body>

</html>
